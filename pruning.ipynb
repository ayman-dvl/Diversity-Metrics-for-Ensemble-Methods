{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7c6454b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import mean\n",
    "from numpy import std\n",
    "from sklearn.datasets import make_moons\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np  \n",
    "import os   \n",
    "import joblib\n",
    "from tensorflow.keras.models import load_model\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from tensorflow.keras.models import Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9618eea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset():\n",
    "    \"\"\"Generate a synthetic dataset using make_moons\"\"\"\n",
    "    X, y = make_moons(n_samples=300, noise=0.2, random_state=42)\n",
    "    return X, y\n",
    "\n",
    "def get_models():\n",
    "    \"\"\"Load models from the 'models' directory\"\"\"\n",
    "    models = {}\n",
    "    models_folder = os.path.join(os.getcwd(), \"models\")\n",
    "    for file in os.listdir(models_folder):\n",
    "        model_name = file.split(\".\")[0]\n",
    "        file_extension = file.split(\".\")[-1]\n",
    "        if file_extension == \"pkl\":\n",
    "            models[model_name] = joblib.load(os.path.join(models_folder, file))\n",
    "            print(f\"Imported sklearn model: {model_name}\")\n",
    "        elif file_extension == \"keras\":\n",
    "            models[model_name] = load_model(os.path.join(models_folder, file))\n",
    "            print(f\"Imported keras model: {model_name}\")\n",
    "    print(models)\n",
    "    return models\n",
    "\n",
    "def custom_soft_voting_predict(models, X):\n",
    "    \"\"\"Custom soft voting prediction for an ensemble of models\"\"\"\n",
    "    probas = []  \n",
    "    for model in models:\n",
    "        if hasattr(model, \"predict_proba\"):\n",
    "            probas.append(model.predict_proba(X))\n",
    "        elif isinstance(model, Sequential): \n",
    "            probas.append(model.predict(X))\n",
    "        else:\n",
    "            print(f\"Model {model} does not support predict_proba and will be skipped.\")\n",
    "    if not probas:\n",
    "        raise ValueError(\"No models in the ensemble support predict_proba.\")\n",
    "    avg_proba = np.mean(probas, axis=0)\n",
    "    return np.argmax(avg_proba, axis=1)\n",
    "\n",
    "def evaluate_ensemble(models, X, y):\n",
    "    \"\"\"\n",
    "    Evaluate an ensemble of models using custom soft voting and return the mean accuracy.\n",
    "    \"\"\"\n",
    "    if len(models) == 0:\n",
    "        return 0.0\n",
    "    model_objects = [model for _, model in models]\n",
    "    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "    scores = []\n",
    "    for train_idx, test_idx in cv.split(X, y):\n",
    "        X_train, X_test = X[train_idx], X[test_idx]\n",
    "        y_train, y_test = y[train_idx], y[test_idx]\n",
    "        for model in model_objects:\n",
    "            model.fit(X_train, y_train)\n",
    "        y_pred = custom_soft_voting_predict(model_objects, X_test)\n",
    "        score = mean(y_pred == y_test)\n",
    "        scores.append(score)\n",
    "    return mean(scores)\n",
    "\n",
    "def calculate_Q_statistic(predictions1, predictions2):\n",
    "    \"\"\"Calculate Q-statistic between two classifiers' predictions\"\"\"\n",
    "    N11 = sum((predictions1 == 1) & (predictions2 == 1))\n",
    "    N00 = sum((predictions1 == 0) & (predictions2 == 0))\n",
    "    N10 = sum((predictions1 == 1) & (predictions2 == 0))\n",
    "    N01 = sum((predictions1 == 0) & (predictions2 == 1))\n",
    "    \n",
    "    Q = (N11 * N00 - N10 * N01) / (N11 * N00 + N10 * N01 + 1e-10)\n",
    "    return Q\n",
    "\n",
    "def get_predictions(model, X, y):\n",
    "    \"\"\"Get binary predictions from a model, handling different prediction attributes\"\"\"\n",
    "    try:\n",
    "        if hasattr(model, 'predict_proba'):\n",
    "            # Models with predict_proba method\n",
    "            y_pred = model.predict_proba(X)[:, 1] > 0.5\n",
    "        elif hasattr(model, 'decision_function'):\n",
    "            # Models with decision_function method\n",
    "            y_pred = model.decision_function(X) > 0\n",
    "        else:\n",
    "            # Fallback to predict method\n",
    "            y_pred = model.predict(X)\n",
    "            if len(y_pred.shape) > 1 and y_pred.shape[1] > 1:\n",
    "                y_pred = y_pred[:, 1] > 0.5\n",
    "        return y_pred.astype(int)\n",
    "    except Exception as e:\n",
    "        print(f\"Error predicting with model: {e}\")\n",
    "        # Fallback to zeros if prediction fails\n",
    "        return np.zeros_like(y)\n",
    "\n",
    "def mean_Q_statistic(models, X, y):\n",
    "    \"\"\"Calculate mean Q-statistic across all pairs of models\"\"\"\n",
    "    n_models = len(models)\n",
    "    if n_models < 2:\n",
    "        return 0.0\n",
    "    \n",
    "    Q_values = []\n",
    "    predictions = []\n",
    "    for model in models:\n",
    "        try:\n",
    "            pred = get_predictions(model[1], X, y)\n",
    "            predictions.append(pred)\n",
    "        except Exception as e:\n",
    "            print(f\"Error getting predictions for model {model[0]}: {e}\")\n",
    "            predictions.append(np.zeros_like(y))  # Fallback to zeros if prediction fails\n",
    "    \n",
    "    for i in range(n_models):\n",
    "        for j in range(i+1, n_models):\n",
    "            Q = calculate_Q_statistic(predictions[i], predictions[j])\n",
    "            Q_values.append(Q)\n",
    "            \n",
    "    return np.mean(Q_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b3010097",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def prune_round(models_in, X, y):\n",
    "    \"\"\"Perform a single round of pruning based on Q-statistic diversity\"\"\"\n",
    "    baseline_acc = evaluate_ensemble(models_in, X, y)\n",
    "    baseline_Q = mean_Q_statistic(models_in, X, y)\n",
    "    best_score = baseline_acc\n",
    "    removed = None\n",
    "    # Try removing each model and evaluate both accuracy and diversity\n",
    "    for m in models_in:\n",
    "        dup = [model for model in models_in if model != m]\n",
    "        \n",
    "        # Calculate new accuracy and Q-statistic\n",
    "        new_acc = evaluate_ensemble(dup, X, y)\n",
    "        new_Q = mean_Q_statistic(dup, X, y)\n",
    "        \n",
    "        # Accept removal if accuracy doesn't decrease significantly (within 1%)\n",
    "        # and diversity improves (lower Q-statistic)\n",
    "        if new_acc >= best_score * 0.99 and new_Q < baseline_Q:\n",
    "            best_score = new_acc\n",
    "            removed = m\n",
    "            baseline_Q = new_Q\n",
    "            \n",
    "    return best_score, removed, baseline_Q\n",
    "\n",
    "def prune_ensemble(models, X, y):\n",
    "    scores = []\n",
    "    Q_stats = []\n",
    "    best_score = 0.0\n",
    "    m_length = len(models)-1\n",
    "    iterations = 0\n",
    "    # prune ensemble until no further improvement or max iterations reached\n",
    "    while iterations < m_length:\n",
    "        # remove one model from the ensemble\n",
    "        score, removed, stat_Q = prune_round(models, X, y)\n",
    "        scores.append(score)\n",
    "        Q_stats.append(stat_Q)\n",
    "        # check for no improvement\n",
    "        if removed is None:\n",
    "            print('>no further improvement')\n",
    "            break\n",
    "        # keep track of best score\n",
    "        best_score = score\n",
    "        list_models = [model for model in models if model != removed] #new\n",
    "        print('>%.3f (removed: %s)' % (score, removed[0]))\n",
    "        iterations += 1\n",
    "    return best_score, list_models, scores, Q_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92d06470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded successfully\n",
      "Imported keras model: cnn_model\n",
      "Imported sklearn model: decision_tree\n",
      "Imported sklearn model: kernel_svc\n",
      "Imported sklearn model: linear_svc\n",
      "Imported sklearn model: random_forest\n",
      "{'cnn_model': <Sequential name=sequential, built=True>, 'decision_tree': DecisionTreeClassifier(), 'kernel_svc': SVC(probability=True), 'linear_svc': LinearSVC(max_iter=10000), 'random_forest': RandomForestClassifier()}\n",
      "done\n",
      "\u001b[1m9/9\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 15ms/step - accuracy: 0.8541 - loss: 0.3618\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
      "Model LinearSVC(max_iter=10000) does not support predict_proba and will be skipped.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (4, 30) + inhomogeneous part.",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[19]\u001b[39m\u001b[32m, line 17\u001b[39m\n\u001b[32m     15\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mdone\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     16\u001b[39m \u001b[38;5;66;03m# run pruning\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m17\u001b[39m score, model_list, scores, Q_stats = \u001b[43mprune_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Plotting\u001b[39;00m\n\u001b[32m     20\u001b[39m plt.figure(figsize=(\u001b[32m12\u001b[39m, \u001b[32m7\u001b[39m))\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 33\u001b[39m, in \u001b[36mprune_ensemble\u001b[39m\u001b[34m(models, X, y)\u001b[39m\n\u001b[32m     30\u001b[39m \u001b[38;5;66;03m# prune ensemble until no further improvement or max iterations reached\u001b[39;00m\n\u001b[32m     31\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m iterations < m_length:\n\u001b[32m     32\u001b[39m     \u001b[38;5;66;03m# remove one model from the ensemble\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m33\u001b[39m     score, removed, stat_Q = \u001b[43mprune_round\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     34\u001b[39m     scores.append(score)\n\u001b[32m     35\u001b[39m     Q_stats.append(stat_Q)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[17]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mprune_round\u001b[39m\u001b[34m(models_in, X, y)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mprune_round\u001b[39m(models_in, X, y):\n\u001b[32m      2\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Perform a single round of pruning based on Q-statistic diversity\"\"\"\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m     baseline_acc = \u001b[43mevaluate_ensemble\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodels_in\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m     baseline_Q = mean_Q_statistic(models_in, X, y)\n\u001b[32m      5\u001b[39m     best_score = baseline_acc\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 51\u001b[39m, in \u001b[36mevaluate_ensemble\u001b[39m\u001b[34m(models, X, y)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m model \u001b[38;5;129;01min\u001b[39;00m model_objects:\n\u001b[32m     50\u001b[39m     model.fit(X_train, y_train)\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m y_pred = \u001b[43mcustom_soft_voting_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_objects\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     52\u001b[39m score = mean(y_pred == y_test)\n\u001b[32m     53\u001b[39m scores.append(score)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 34\u001b[39m, in \u001b[36mcustom_soft_voting_predict\u001b[39m\u001b[34m(models, X)\u001b[39m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m probas:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mNo models in the ensemble support predict_proba.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m avg_proba = \u001b[43mnp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprobas\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m np.argmax(avg_proba, axis=\u001b[32m1\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\DOCS_ayman\\proj\\.venv\\Lib\\site-packages\\numpy\\_core\\fromnumeric.py:3904\u001b[39m, in \u001b[36mmean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m   3901\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   3902\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m mean(axis=axis, dtype=dtype, out=out, **kwargs)\n\u001b[32m-> \u001b[39m\u001b[32m3904\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_methods\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_mean\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m=\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   3905\u001b[39m \u001b[43m                      \u001b[49m\u001b[43mout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mout\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\DOCS_ayman\\proj\\.venv\\Lib\\site-packages\\numpy\\_core\\_methods.py:120\u001b[39m, in \u001b[36m_mean\u001b[39m\u001b[34m(a, axis, dtype, out, keepdims, where)\u001b[39m\n\u001b[32m    119\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_mean\u001b[39m(a, axis=\u001b[38;5;28;01mNone\u001b[39;00m, dtype=\u001b[38;5;28;01mNone\u001b[39;00m, out=\u001b[38;5;28;01mNone\u001b[39;00m, keepdims=\u001b[38;5;28;01mFalse\u001b[39;00m, *, where=\u001b[38;5;28;01mTrue\u001b[39;00m):\n\u001b[32m--> \u001b[39m\u001b[32m120\u001b[39m     arr = \u001b[43masanyarray\u001b[49m\u001b[43m(\u001b[49m\u001b[43ma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    122\u001b[39m     is_float16_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    124\u001b[39m     rcount = _count_reduce_items(arr, axis, keepdims=keepdims, where=where)\n",
      "\u001b[31mValueError\u001b[39m: setting an array element with a sequence. The requested array has an inhomogeneous shape after 2 dimensions. The detected shape was (4, 30) + inhomogeneous part."
     ]
    }
   ],
   "source": [
    "# Main execution code\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    # define dataset\n",
    "    X, y = get_dataset()\n",
    "    print(\"Dataset loaded successfully\")\n",
    "    \n",
    "    # get the models to evaluate\n",
    "    models = get_models()\n",
    "    # Use the predefined models variable\n",
    "    if not models:\n",
    "        raise ValueError(\"No models found in the predefined models list\")\n",
    "    # convert models dict to list of tuples\n",
    "    models = [(name, model) for name, model in models.items()]\n",
    "    print('done')\n",
    "    # run pruning\n",
    "    score, model_list, scores, Q_stats = prune_ensemble(models, X, y)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(12, 7))\n",
    "    plt.plot(scores, label='Accuracy Scores', linestyle='-', linewidth=2, color='red', marker='o')\n",
    "    plt.plot(Q_stats, label='Q-Statistics', linestyle='-', linewidth=2, color='blue', marker='s')\n",
    "    plt.xlabel('Iteration', fontsize=12)\n",
    "    plt.ylabel('Value', fontsize=12)\n",
    "    plt.title('Accuracy Scores and Q-Statistics Over Iterations', fontsize=14, pad=20)\n",
    "    plt.legend(loc='center right', bbox_to_anchor=(1.15, 0.5))\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    # Calculate remaining model diversity\n",
    "    final_Q = mean_Q_statistic([model for _, model in model_list], X, y)\n",
    "    print('Final Q-statistic: %.3f' % final_Q)\n",
    "    # Print results\n",
    "    names = ','.join([n for n, _ in model_list])\n",
    "    print('Remaining Models: %s' % names)\n",
    "    print('Final Mean Accuracy: %.3f' % score)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197fa660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
